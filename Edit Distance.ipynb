{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316861f9-5eaf-4675-8a43-991a8197e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f31e96b-ce7b-41da-8f6e-bb602e1b9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_to_words(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "    data = data.lower()\n",
    "    words = re.findall(r'\\w+', data)\n",
    "    return words\n",
    "\n",
    "def count_word_occurence(words):\n",
    "    word_counts = {}\n",
    "    for w in words:\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    return word_counts\n",
    "\n",
    "def word_proba(word_counts):\n",
    "    word_proba = {}\n",
    "    unique_words = sum(word_counts.values())\n",
    "    for w, count in word_counts.items():\n",
    "        word_proba[w] = count / unique_words\n",
    "    return word_proba\n",
    "\n",
    "def edit_delete(word, pos):\n",
    "    return word[:pos] + word[pos + 1:]\n",
    "\n",
    "def edit_switch(word, pos1, pos2):\n",
    "    if len(word) > 1:\n",
    "        word_list = list(word)\n",
    "        word_list[pos1], word_list[pos2] = word_list[pos2], word_list[pos1]\n",
    "        return ''.join(word_list)\n",
    "    return word\n",
    "\n",
    "def edit_replace(word, pos, l):\n",
    "    return word[:pos] + l + word[pos + 1:]\n",
    "\n",
    "def one_edit(word):\n",
    "    edits = set()\n",
    "    for pos in range(len(word)):\n",
    "        edits.add(edit_delete(word, pos))\n",
    "    for pos1 in range(len(word) - 1):\n",
    "        edits.add(edit_switch(word, pos1, pos1 + 1))\n",
    "    for pos in range(len(word)):\n",
    "        for l in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            edits.add(edit_replace(word, pos, l))\n",
    "    return edits\n",
    "\n",
    "def two_edits(word):\n",
    "    two_edit_set = set()\n",
    "    for w in one_edit(word):\n",
    "        two_edit_set.update(one_edit(w))\n",
    "    return two_edit_set\n",
    "\n",
    "def top_corrections(incorrect_word, vocab, word_probabilities, top_k):\n",
    "    suggestions = set()\n",
    "    \n",
    "    if incorrect_word in vocab:\n",
    "        suggestions.add(incorrect_word)\n",
    "    \n",
    "    suggestions.update(one_edit(incorrect_word).intersection(vocab))\n",
    "    suggestions.update(two_edits(incorrect_word).intersection(vocab))\n",
    "    \n",
    "    best_words = {s: word_probabilities.get(s, 0) for s in suggestions}\n",
    "    \n",
    "    top_suggestions = sorted(best_words.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    return top_suggestions\n",
    "\n",
    "def min_edit_distance(start_str, end_str, insert_cost=1, delete_cost=1, replace_cost=2):\n",
    "    start_len = len(start_str)\n",
    "    end_len = len(end_str)\n",
    "    cost_matrix = np.zeros((start_len+1, end_len+1))\n",
    "\n",
    "    for i in range(1, start_len+1):\n",
    "        cost_matrix[i, 0] = cost_matrix[i-1, 0] + delete_cost\n",
    "\n",
    "    for j in range(1, end_len+1):\n",
    "        cost_matrix[0, j] = cost_matrix[0, j-1] + insert_cost\n",
    "\n",
    "    for i in range(1, start_len+1):\n",
    "        for j in range(1, end_len+1):\n",
    "            \n",
    "           \n",
    "            if start_str[i-1] == end_str[j-1]:\n",
    "                diag_cost=cost_matrix[i-1, j-1]\n",
    "            else:\n",
    "                diag_cost=cost_matrix[i-1, j-1]+replace_cost\n",
    "            cost_matrix[i, j] = min(cost_matrix[i-1, j] + delete_cost, \n",
    "                                    cost_matrix[i, j-1] + insert_cost, \n",
    "                                    diag_cost)\n",
    "\n",
    "    \n",
    "    return cost_matrix, cost_matrix[start_len, end_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6863878-2755-45d9-8729-e861049f6203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('my', 0.01600328272466147), ('is', 0.010389077479762749)]\n"
     ]
    }
   ],
   "source": [
    "words = preprocess_data_to_words('shakespeare.txt')\n",
    "word_counts = count_word_occurence(words)\n",
    "word_probabilities = word_proba(word_counts)\n",
    "\n",
    "edit_del = [edit_delete(w, pos) for w in word_counts.keys() if len(w) > 1 for pos in range(len(w))]\n",
    "edit_switchs = [edit_switch(w, pos1, pos2) for w in word_counts.keys() for pos1 in range(len(w)) for pos2 in range(pos1 + 1, len(w))]\n",
    "edit_rep = [edit_replace(w, pos1, l) for w in word_counts.keys() for pos1 in range(len(w)) for l in 'abcdefghijklmnopqrstuvwxyz']\n",
    "\n",
    "corrections = top_corrections('dys', set(word_counts.keys()), word_probabilities, top_k=2)\n",
    "print(corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54845f0-9a1d-4056-b857-a23c03b75fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
